{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7021f8c1-6e7b-448c-8e15-5090c97f5ac0",
   "metadata": {},
   "source": [
    "#### Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33294a0a-e24c-4a92-892e-a2ef3f0e897c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that an employee is a smoker given that they use the health insurance plan: 0.39999999999999997\n"
     ]
    }
   ],
   "source": [
    "# Calculation of probability using provided information\n",
    "p_use_plan = 0.70  # Probability that an employee uses the health insurance plan\n",
    "p_smoker_given_use_plan = 0.40  # Probability that an employee is a smoker given that they use the health insurance plan\n",
    "\n",
    "# Calculation of the probability using Bayes' theorem\n",
    "p_smoker_and_use_plan = p_use_plan * p_smoker_given_use_plan  # P(Smoker and Use Plan)\n",
    "p_use_plan_given_smoker = p_smoker_and_use_plan / p_use_plan  # P(Use Plan | Smoker)\n",
    "\n",
    "# Printing the result\n",
    "print(\"Probability that an employee is a smoker given that they use the health insurance plan:\", p_use_plan_given_smoker)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b724052-5450-407f-8295-3d42e4a7abd6",
   "metadata": {},
   "source": [
    "#### Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9ab04b-39fc-4364-adfe-faca10235c30",
   "metadata": {},
   "source": [
    "Ans--> The main difference between Bernoulli Naive Bayes and Multinomial Naive Bayes lies in the type of data they are suitable for and the underlying assumptions they make. Here are the key differences:\n",
    "\n",
    "1. Data Type:\n",
    "   - Bernoulli Naive Bayes: It is suitable for binary or Boolean features, where each feature represents the presence or absence of a particular attribute. It works with data where features are binary indicators (0 or 1) of the presence or absence of certain attributes.\n",
    "   - Multinomial Naive Bayes: It is suitable for discrete count data, typically represented by word frequencies or occurrence counts. It works with data where features represent counts or frequencies of events or categories.\n",
    "\n",
    "2. Feature Representation:\n",
    "   - Bernoulli Naive Bayes: It assumes that each feature follows a Bernoulli distribution, meaning that features are binary indicators. It considers the presence or absence of a feature in a document.\n",
    "   - Multinomial Naive Bayes: It assumes that features follow a multinomial distribution, where each feature represents the count or frequency of a specific event or category. It considers the occurrence count or frequency of each feature.\n",
    "\n",
    "3. Assumptions:\n",
    "   - Bernoulli Naive Bayes: It assumes that features are independent of each other given the class variable. It treats features as binary indicators and assumes that the presence or absence of one feature does not affect the presence or absence of other features.\n",
    "   - Multinomial Naive Bayes: It assumes that features are independent of each other given the class variable. It assumes that the occurrence counts or frequencies of different features are conditionally independent given the class.\n",
    "\n",
    "4. Application:\n",
    "   - Bernoulli Naive Bayes: It is commonly used in text classification tasks where the presence or absence of certain words or features is considered, such as sentiment analysis or document classification with binary bag-of-words representation.\n",
    "   - Multinomial Naive Bayes: It is widely used in text classification problems where word frequencies or occurrence counts are important, such as document categorization or spam filtering based on the count of words.\n",
    "\n",
    "In summary, Bernoulli Naive Bayes is suitable for binary feature data, while Multinomial Naive Bayes is suitable for discrete count data. Bernoulli Naive Bayes considers the presence or absence of features, while Multinomial Naive Bayes considers the occurrence counts or frequencies. The choice between the two depends on the nature of the data and the specific problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cf55d3-469d-4f43-aa3e-d66236216cf7",
   "metadata": {},
   "source": [
    "#### Q3. How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53c0a97-400a-4a93-aeac-1727fff19dbb",
   "metadata": {},
   "source": [
    "Ans--> Bernoulli Naive Bayes does not handle missing values explicitly. It assumes that each feature follows a Bernoulli distribution, where features are binary indicators representing the presence or absence of a particular attribute. In this formulation, missing values are typically treated as a separate category or class.\n",
    "\n",
    "When dealing with missing values in Bernoulli Naive Bayes, there are a few common approaches:\n",
    "\n",
    "1. Assign a default or special value: Replace missing values with a specific value that represents missingness, such as \"NaN\" or \"unknown\". This allows the missing values to be treated as a separate category during the training and prediction phases.\n",
    "\n",
    "2. Ignore missing values: Alternatively, you can choose to ignore instances with missing values during the training and prediction stages. This means removing instances with missing values from the dataset before applying the Bernoulli Naive Bayes algorithm.\n",
    "\n",
    "3. Imputation: Another option is to impute the missing values with some estimated values. This can be done by using various imputation techniques, such as mean imputation (replacing missing values with the mean of the feature) or regression imputation (predicting the missing values based on other features).\n",
    "\n",
    "The choice of handling missing values in Bernoulli Naive Bayes depends on the specific problem, the amount and nature of missingness in the data, and the available information. It is important to consider the potential impact of missing values on the accuracy and reliability of the classification results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1031bf36-a38f-4cc8-8d4a-e05aea205769",
   "metadata": {},
   "source": [
    "#### Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b2a8d1-5165-4445-bd92-3b09ac56498c",
   "metadata": {},
   "source": [
    "Ans--> Yes, Gaussian Naive Bayes can be used for multi-class classification. Gaussian Naive Bayes is an extension of Naive Bayes algorithm that assumes the features are continuous and follows a Gaussian distribution. It is commonly used for classification tasks where the features have continuous values.\n",
    "\n",
    "In the case of multi-class classification, where there are more than two classes to predict, Gaussian Naive Bayes can be adapted to handle multiple classes. The algorithm calculates the probability of each class given the input features and selects the class with the highest probability as the predicted class.\n",
    "\n",
    "To use Gaussian Naive Bayes for multi-class classification, the algorithm estimates the class conditional probability distribution for each class using the Gaussian distribution assumption. Then, when making predictions, it calculates the probability of each class for a given input and selects the class with the highest probability.\n",
    "\n",
    "While Gaussian Naive Bayes can be effective for some types of data and classification problems, it makes strong assumptions about the independence of features, which may not hold in all cases. Additionally, it assumes that the features follow a Gaussian distribution, which may not be the case for all datasets. Therefore, it's important to assess whether these assumptions are valid for your specific dataset before applying Gaussian Naive Bayes for multi-class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f868c6-fbfa-45ba-9809-cda933785a8a",
   "metadata": {},
   "source": [
    "#### Q5. Assignment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddf6579-3f3b-4952-8863-1d789f98c159",
   "metadata": {},
   "source": [
    "#### Data preparation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86136e55-cc27-4fa9-96f9-fd0320df9ead",
   "metadata": {},
   "source": [
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "is spam or not based on several input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c62364-0bc6-4010-8aee-b2deb5da4ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22476a01-7961-4bd2-b098-e44ed5e48d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam=pd.read_csv('spambase.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c820207-097d-4684-9b16-326547565a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.64.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.45</th>\n",
       "      <th>3.756</th>\n",
       "      <th>61</th>\n",
       "      <th>278</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...  0.41  \\\n",
       "0  0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "1  0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "2  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "3  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00    0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00  ...  0.00   \n",
       "\n",
       "    0.42  0.43  0.778   0.44   0.45  3.756   61   278  1  \n",
       "0  0.132   0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
       "1  0.143   0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
       "2  0.137   0.0  0.137  0.000  0.000  3.537   40   191  1  \n",
       "3  0.135   0.0  0.135  0.000  0.000  3.537   40   191  1  \n",
       "4  0.223   0.0  0.000  0.000  0.000  3.000   15    54  1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61a05a10-f58d-4fac-bf13-77e6fe149517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 58 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       4600 non-null   float64\n",
      " 1   0.64    4600 non-null   float64\n",
      " 2   0.64.1  4600 non-null   float64\n",
      " 3   0.1     4600 non-null   float64\n",
      " 4   0.32    4600 non-null   float64\n",
      " 5   0.2     4600 non-null   float64\n",
      " 6   0.3     4600 non-null   float64\n",
      " 7   0.4     4600 non-null   float64\n",
      " 8   0.5     4600 non-null   float64\n",
      " 9   0.6     4600 non-null   float64\n",
      " 10  0.7     4600 non-null   float64\n",
      " 11  0.64.2  4600 non-null   float64\n",
      " 12  0.8     4600 non-null   float64\n",
      " 13  0.9     4600 non-null   float64\n",
      " 14  0.10    4600 non-null   float64\n",
      " 15  0.32.1  4600 non-null   float64\n",
      " 16  0.11    4600 non-null   float64\n",
      " 17  1.29    4600 non-null   float64\n",
      " 18  1.93    4600 non-null   float64\n",
      " 19  0.12    4600 non-null   float64\n",
      " 20  0.96    4600 non-null   float64\n",
      " 21  0.13    4600 non-null   float64\n",
      " 22  0.14    4600 non-null   float64\n",
      " 23  0.15    4600 non-null   float64\n",
      " 24  0.16    4600 non-null   float64\n",
      " 25  0.17    4600 non-null   float64\n",
      " 26  0.18    4600 non-null   float64\n",
      " 27  0.19    4600 non-null   float64\n",
      " 28  0.20    4600 non-null   float64\n",
      " 29  0.21    4600 non-null   float64\n",
      " 30  0.22    4600 non-null   float64\n",
      " 31  0.23    4600 non-null   float64\n",
      " 32  0.24    4600 non-null   float64\n",
      " 33  0.25    4600 non-null   float64\n",
      " 34  0.26    4600 non-null   float64\n",
      " 35  0.27    4600 non-null   float64\n",
      " 36  0.28    4600 non-null   float64\n",
      " 37  0.29    4600 non-null   float64\n",
      " 38  0.30    4600 non-null   float64\n",
      " 39  0.31    4600 non-null   float64\n",
      " 40  0.33    4600 non-null   float64\n",
      " 41  0.34    4600 non-null   float64\n",
      " 42  0.35    4600 non-null   float64\n",
      " 43  0.36    4600 non-null   float64\n",
      " 44  0.37    4600 non-null   float64\n",
      " 45  0.38    4600 non-null   float64\n",
      " 46  0.39    4600 non-null   float64\n",
      " 47  0.40    4600 non-null   float64\n",
      " 48  0.41    4600 non-null   float64\n",
      " 49  0.42    4600 non-null   float64\n",
      " 50  0.43    4600 non-null   float64\n",
      " 51  0.778   4600 non-null   float64\n",
      " 52  0.44    4600 non-null   float64\n",
      " 53  0.45    4600 non-null   float64\n",
      " 54  3.756   4600 non-null   float64\n",
      " 55  61      4600 non-null   int64  \n",
      " 56  278     4600 non-null   int64  \n",
      " 57  1       4600 non-null   int64  \n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "spam.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa576741-3f3b-4586-9630-9e6fdad24df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.64.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.45</th>\n",
       "      <th>3.756</th>\n",
       "      <th>61</th>\n",
       "      <th>278</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104576</td>\n",
       "      <td>0.212922</td>\n",
       "      <td>0.280578</td>\n",
       "      <td>0.065439</td>\n",
       "      <td>0.312222</td>\n",
       "      <td>0.095922</td>\n",
       "      <td>0.114233</td>\n",
       "      <td>0.105317</td>\n",
       "      <td>0.090087</td>\n",
       "      <td>0.239465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038583</td>\n",
       "      <td>0.139061</td>\n",
       "      <td>0.016980</td>\n",
       "      <td>0.268960</td>\n",
       "      <td>0.075827</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>5.191827</td>\n",
       "      <td>52.170870</td>\n",
       "      <td>283.290435</td>\n",
       "      <td>0.393913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305387</td>\n",
       "      <td>1.290700</td>\n",
       "      <td>0.504170</td>\n",
       "      <td>1.395303</td>\n",
       "      <td>0.672586</td>\n",
       "      <td>0.273850</td>\n",
       "      <td>0.391480</td>\n",
       "      <td>0.401112</td>\n",
       "      <td>0.278643</td>\n",
       "      <td>0.644816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243497</td>\n",
       "      <td>0.270377</td>\n",
       "      <td>0.109406</td>\n",
       "      <td>0.815726</td>\n",
       "      <td>0.245906</td>\n",
       "      <td>0.429388</td>\n",
       "      <td>31.732891</td>\n",
       "      <td>194.912453</td>\n",
       "      <td>606.413764</td>\n",
       "      <td>0.488669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.275500</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314250</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.705250</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>265.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         0.64       0.64.1          0.1         0.32  \\\n",
       "count  4600.000000  4600.000000  4600.000000  4600.000000  4600.000000   \n",
       "mean      0.104576     0.212922     0.280578     0.065439     0.312222   \n",
       "std       0.305387     1.290700     0.504170     1.395303     0.672586   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.420000     0.000000     0.382500   \n",
       "max       4.540000    14.280000     5.100000    42.810000    10.000000   \n",
       "\n",
       "               0.2          0.3          0.4          0.5          0.6  ...  \\\n",
       "count  4600.000000  4600.000000  4600.000000  4600.000000  4600.000000  ...   \n",
       "mean      0.095922     0.114233     0.105317     0.090087     0.239465  ...   \n",
       "std       0.273850     0.391480     0.401112     0.278643     0.644816  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.160000  ...   \n",
       "max       5.880000     7.270000    11.110000     5.260000    18.180000  ...   \n",
       "\n",
       "              0.41         0.42         0.43        0.778         0.44  \\\n",
       "count  4600.000000  4600.000000  4600.000000  4600.000000  4600.000000   \n",
       "mean      0.038583     0.139061     0.016980     0.268960     0.075827   \n",
       "std       0.243497     0.270377     0.109406     0.815726     0.245906   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.065000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.188000     0.000000     0.314250     0.052000   \n",
       "max       4.385000     9.752000     4.081000    32.478000     6.003000   \n",
       "\n",
       "              0.45        3.756           61           278            1  \n",
       "count  4600.000000  4600.000000  4600.000000   4600.000000  4600.000000  \n",
       "mean      0.044248     5.191827    52.170870    283.290435     0.393913  \n",
       "std       0.429388    31.732891   194.912453    606.413764     0.488669  \n",
       "min       0.000000     1.000000     1.000000      1.000000     0.000000  \n",
       "25%       0.000000     1.588000     6.000000     35.000000     0.000000  \n",
       "50%       0.000000     2.275500    15.000000     95.000000     0.000000  \n",
       "75%       0.000000     3.705250    43.000000    265.250000     1.000000  \n",
       "max      19.829000  1102.500000  9989.000000  15841.000000     1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec13cd87-e65e-45d3-bb0a-8f1822e99e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "0.64      0\n",
       "0.64.1    0\n",
       "0.1       0\n",
       "0.32      0\n",
       "0.2       0\n",
       "0.3       0\n",
       "0.4       0\n",
       "0.5       0\n",
       "0.6       0\n",
       "0.7       0\n",
       "0.64.2    0\n",
       "0.8       0\n",
       "0.9       0\n",
       "0.10      0\n",
       "0.32.1    0\n",
       "0.11      0\n",
       "1.29      0\n",
       "1.93      0\n",
       "0.12      0\n",
       "0.96      0\n",
       "0.13      0\n",
       "0.14      0\n",
       "0.15      0\n",
       "0.16      0\n",
       "0.17      0\n",
       "0.18      0\n",
       "0.19      0\n",
       "0.20      0\n",
       "0.21      0\n",
       "0.22      0\n",
       "0.23      0\n",
       "0.24      0\n",
       "0.25      0\n",
       "0.26      0\n",
       "0.27      0\n",
       "0.28      0\n",
       "0.29      0\n",
       "0.30      0\n",
       "0.31      0\n",
       "0.33      0\n",
       "0.34      0\n",
       "0.35      0\n",
       "0.36      0\n",
       "0.37      0\n",
       "0.38      0\n",
       "0.39      0\n",
       "0.40      0\n",
       "0.41      0\n",
       "0.42      0\n",
       "0.43      0\n",
       "0.778     0\n",
       "0.44      0\n",
       "0.45      0\n",
       "3.756     0\n",
       "61        0\n",
       "278       0\n",
       "1         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c183fa7-0a5b-4feb-bb80-c771c8100488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "0.64      0\n",
       "0.64.1    0\n",
       "0.1       0\n",
       "0.32      0\n",
       "0.2       0\n",
       "0.3       0\n",
       "0.4       0\n",
       "0.5       0\n",
       "0.6       0\n",
       "0.7       0\n",
       "0.64.2    0\n",
       "0.8       0\n",
       "0.9       0\n",
       "0.10      0\n",
       "0.32.1    0\n",
       "0.11      0\n",
       "1.29      0\n",
       "1.93      0\n",
       "0.12      0\n",
       "0.96      0\n",
       "0.13      0\n",
       "0.14      0\n",
       "0.15      0\n",
       "0.16      0\n",
       "0.17      0\n",
       "0.18      0\n",
       "0.19      0\n",
       "0.20      0\n",
       "0.21      0\n",
       "0.22      0\n",
       "0.23      0\n",
       "0.24      0\n",
       "0.25      0\n",
       "0.26      0\n",
       "0.27      0\n",
       "0.28      0\n",
       "0.29      0\n",
       "0.30      0\n",
       "0.31      0\n",
       "0.33      0\n",
       "0.34      0\n",
       "0.35      0\n",
       "0.36      0\n",
       "0.37      0\n",
       "0.38      0\n",
       "0.39      0\n",
       "0.40      0\n",
       "0.41      0\n",
       "0.42      0\n",
       "0.43      0\n",
       "0.778     0\n",
       "0.44      0\n",
       "0.45      0\n",
       "3.756     0\n",
       "61        0\n",
       "278       0\n",
       "1         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e13e6df3-c97b-42e8-b646-76ac63ca2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=spam.drop('1',axis=1)\n",
    "y=spam['1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b55dab-3601-4a92-9491-e133220490f8",
   "metadata": {},
   "source": [
    "##### Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d538ed39-844c-4903-bc3b-3dea963e0799",
   "metadata": {},
   "source": [
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58be616a-5cbd-49f1-bcfb-1d42c18a7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2f91b57-56cd-488d-bce7-98900b49a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a460dd6e-72ba-4d96-9417-e05bedc3be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "bernaulliNb=BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53dbb04b-3401-4ee5-b5af-53de72513757",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=cross_val_score(bernaulliNb,x_train,y_train,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4831c57-4ff1-4004-9039-c5e118f4e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b040a44e-b1cf-4b57-a599-d7150889007f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8891304347826086"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12154d59-14d7-4d69-b364-ca7f12baf0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomialNb=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33edb952-368d-47fe-9e34-45f73ebc7ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=cross_val_score(multinomialNb,x_train,y_train,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f1fc308-893b-4070-9d6b-c54fb2cc2856",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbb91651-6923-4be4-8b61-2f526710b156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7953804347826087"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51bd13a7-8689-458e-80b3-0c3ac06bd56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussianNb=GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2afdedb0-be0a-4cae-93b9-3744f6baa20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=cross_val_score(gaussianNb,x_train,y_train,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce7e32c9-eecf-4024-9d2a-bf339102bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b72909ef-ca82-4a65-a8a8-8162f0416dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8220108695652174"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "935e64e2-c664-4f17-889b-e7b11fe0c12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernaulliNb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08060e39-78dd-4557-a523-996fe3fbb7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "453398e5-a6d1-4440-bffd-6b141ca3fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, bernaulliNb.predict(x_test))\n",
    "recall = recall_score(y_test, bernaulliNb.predict(x_test))\n",
    "f1 = f1_score(y_test, bernaulliNb.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b880f4-ef49-4e83-9905-67557adf2a1e",
   "metadata": {},
   "source": [
    "#### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c37bff1-61e8-4964-b073-ab4007dcb7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8728260869565218\n",
      "Precision: 0.8933717579250721\n",
      "Recall: 0.7948717948717948\n",
      "F1-Score: 0.841248303934871\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",accuracy_score(y_test,bernaulliNb.predict(x_test)))\n",
    "print(\"Precision:\",precision)\n",
    "print(\"Recall:\",recall)\n",
    "print(\"F1-Score:\",f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d90e5f0-fc2f-4944-94af-ae1a49a6cdc6",
   "metadata": {},
   "source": [
    "##### Discussion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79677f21-2b95-4fbf-8fa4-fb9f8a7b3881",
   "metadata": {},
   "source": [
    "BernaoulliNb is performed better in terms of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d310675-8202-4f77-896b-cd6d53b25a51",
   "metadata": {},
   "source": [
    "##### Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0913f721-fff1-4f1f-a1e3-54e62c5852ef",
   "metadata": {},
   "source": [
    "Naive Bayes that you observed, such as the assumptions of independence between features and the Gaussian distribution assumption for Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7662eb-8588-4742-b3a6-903684718693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
